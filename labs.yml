---
name: remorph
description: Code Transpiler and Data Reconciliation tool for Accelerating Data onboarding to Databricks from EDW, CDW and other ETL sources.
install:
  min_runtime_version: 13.3
  require_running_cluster: false
  require_databricks_connect: true
  script: src/databricks/labs/remorph/install.py
uninstall:
  script: src/databricks/labs/remorph/uninstall.py
entrypoint: src/databricks/labs/remorph/cli.py
min_python: 3.10
commands:
  - name: transpile
    description: Transpile SQL script to Databricks SQL
    flags:
      - name: source
        description: Input SQL Dialect Type Accepted Values [snowflake, tsql]
      - name: input-sql
        description: Input SQL Folder or File
      - name: output-folder
        default: None
        description: Output Location For Storing Transpiled Cod
      - name: skip-validation
        default: true
        description: Validate Transpiled Code, default True validation skipped, False validate
      - name: catalog-name
        default: None
        description: Catalog Name Applicable only when Validation Mode is DATABRICKS
      - name: schema-name
        default: None
        description: Schema Name Applicable only when Validation Mode is DATABRICKS
      - name: mode
        default: current
        description: Run in Current or Experimental Mode, Accepted Values [experimental, current], Default current, experimental mode will execute including any Private Preview features

    table_template: |-
      total_files_processed\ttotal_queries_processed\tno_of_sql_failed_while_parsing\tno_of_sql_failed_while_validating\terror_log_file
      {{range .}}{{.total_files_processed}}\t{{.total_queries_processed}}\t{{.no_of_sql_failed_while_parsing}}\t{{.no_of_sql_failed_while_validating}}\t{{.error_log_file}}
      {{end}}
  - name: reconcile
    description: Reconcile is an utility to streamline the reconciliation process between source data and target data residing on Databricks.
  - name: aggregates-reconcile
    description: Aggregates Reconcile is an utility to streamline the reconciliation process, specific aggregate metric is compared between source and target data residing on Databricks.
  - name: generate-lineage
    description: Utility to generate a lineage of the SQL files
    flags:
      - name: source
        description: Input SQL Dialect Type Accepted Values [snowflake, tsql]
      - name: input-sql
        description: Input SQL Folder or File
      - name: output-folder
        description: Directory to store the generated lineage file
  - name: configure-secrets
    description: Utility to setup Scope and Secrets on Databricks Workspace
  - name: debug-script
    description: "[INTERNAL] Debug Script"
    flags:
      - name: name
        description: Filename to debug
      - name: dialect
        description: sql dialect
  - name: debug-me
    description: "[INTERNAL] Debug SDK connectivity"
  - name: debug-coverage
    description: "[INTERNAL] Run coverage tests"
    flags:
      - name: src
        description: The parent directory under which test queries are laid out
      - name: dst
        description: The directory under which the report files will be written
      - name: extractor
        description: The strategy for extracting queries from the test files. Valid strategies are "full" (when files contain only one input query) and "comment" (when files contain an input query and the corresponding translation, separated by a comment stating the dialect of each query).
